# IA_Generative_Surveillance

---

# ğŸ§© Objectif du Projet

**Ce projet a pour objectif de mettre en place un benchmark vidÃ©o basÃ© sur le dataset UCF Crimes, permettant :**

- Lâ€™extraction et le redimensionnement des frames dâ€™une vidÃ©o.
- La gÃ©nÃ©ration dâ€™un embedding vectoriel pour chaque frame Ã  lâ€™aide dâ€™un modÃ¨le CLIP.
- La recherche sÃ©mantique via similaritÃ© entre un texte et les images extraites.
- Lâ€™Ã©valuation de robustesse via ajout de bruit ou de modifications artificielles.

---

# âš™ï¸ DÃ©pendances

**Les bibliothÃ¨ques suivantes sont nÃ©cessaires au bon fonctionnement :**

- opencv-python
- torch
- transformers
- sentence-transformers
- chromadb
- numpy
- Pillow
- shutil
- datetime
- os
- cv2
- clip

---

# ğŸ“‚ Structure Principale du Projet

## ğŸ”§ 1. ParamÃ¨tres de configuration
```
FPS_TARGET = 24   # Frame rate cible
TARGET_SIZE = (640, 360)  # Dimensions de sortie des frames
```
## ğŸ“ 2. Extraction et redimensionnement des frames

**Fonctions :**

- `extract_and_resize_frames(...)`: extrait les frames dâ€™une vidÃ©o, les redimensionne, et les stocke dans un dossier.
- `resize_frame(...)`: resize une frame unique Ã  la taille cible.

**ğŸ” Points techniques :**

- Gestion automatique des FPS et adaptation de start_frame.
- CrÃ©ation dâ€™un rÃ©pertoire unique pour stocker les frames (via `create_unique_folder`).

## ğŸ“¹ 3. GÃ©nÃ©ration vidÃ©o Ã  partir de frames
```
create_video_from_frames(frames_dir, output_path, fps)
```
Permet de recrÃ©er une vidÃ©o Ã  partir des images traitÃ©es.

---

# ğŸ¤– Encodage et SimilaritÃ©

## ğŸ’¡ Encodage

- Utilisation du modÃ¨le OpenAI CLIP (`openai/clip-vit-base-patch32`) pour produire des embeddings vectoriels Ã  partir dâ€™images et de textes.
- Normalisation des vecteurs (`L2 norm`) aprÃ¨s encodage.

## ğŸ” Recherche sÃ©mantique

`find_similar_images(frames_dir, query_embedding, similarity_threshold, top_x)`
Calcule la similaritÃ© entre lâ€™embedding texte (`query_embedding`) et ceux de chaque image dans la base de donnÃ©es vectorielle (`ChromaDB`).

**Deux critÃ¨res :**

- Images au-dessus du seuil (`similarity_threshold`)
- Top X images les plus similaires

**âœ… Le systÃ¨me adapte dynamiquement le seuil si demandÃ©, en retirant 10% Ã  la similaritÃ© maximale dÃ©tectÃ©e.**

---

# ğŸ§ª Tests de Robustesse

**Fonction intÃ©grÃ©e :**

`add_salt_pepper_noise(image, amount=0.05)`
- Ajoute un bruit de type "sel et poivre" Ã  une image.
- Permet de tester la robustesse de la reconnaissance visuelle par similaritÃ©.

---

# ğŸ’¾ Stockage vectoriel avec ChromaDB

- Utilisation de Chroma comme base de donnÃ©es vectorielle.
- Les vecteurs sont insÃ©rÃ©s avec leurs mÃ©tadonnÃ©es, ce qui permet une rÃ©cupÃ©ration simple de lâ€™image associÃ©e.
- Si aucune mÃ©tadonnÃ©e nâ€™est stockÃ©e, on peut utiliser les noms de fichiers comme identifiants pour retrouver lâ€™image dâ€™origine.

--- 

# ğŸ”„ Pipeline Complet

1. Charger une vidÃ©o
2. Extraire & redimensionner les frames
3. Encoder chaque frame (image â†’ vecteur)
4. InsÃ©rer les embeddings dans ChromaDB
5. Encoder la requÃªte (texte â†’ vecteur)
6. Calcul des similaritÃ©s (cosine)
7. Filtrage des images (top-k ou seuil dynamique)
8. Reconstruction dâ€™une vidÃ©o ou affichage

--- 

# ğŸš€ Guide dâ€™utilisation du programme

Cette section dÃ©crit comment utiliser le systÃ¨me Ã©tape par Ã©tape, depuis lâ€™entrÃ©e dâ€™une vidÃ©o jusquâ€™Ã  lâ€™obtention des rÃ©sultats de similaritÃ©.

## 1. ğŸ“¥ PrÃ©parer votre vidÃ©o

Placez votre vidÃ©o dans un dossier accessible, par exemple :
`video_path = "path/to/your/video.mp4"`

## 2. ğŸ–¼ï¸ Extraire et redimensionner les frames

Appelez la fonction suivante :
```
frames_dir = extract_and_resize_frames(
    video_path=video_path,
    output_dir="path/to/output/frames",
    target_fps=FPS_TARGET,
    target_size=TARGET_SIZE,
    start_frame=0  # optionnel
)
```
Cela extrait les frames, les redimensionne et les stocke dans un dossier.

## 3. ğŸ” Encoder les images extraites

Parcourez le dossier de frames pour encoder chaque image via CLIP :
```
for frame in os.listdir(frames_dir):
    image_path = os.path.join(frames_dir, frame)
    embedding = encode_image(image_path)  # ou via votre classe
    # InsÃ©rez dans ChromaDB avec image_id = nom du fichier
```

## 4. ğŸ’¬ Entrer une requÃªte texte

Encodez votre requÃªte :
```
query = "Person walking in a park"
query_embedding = get_text_embedding(query)
```

## 5. ğŸ§  Trouver les images similaires

Appelez la fonction de comparaison :
```
find_similar_images(
    frames_dir=frames_dir,
    query_embedding=query_embedding,
    similarity_threshold=None,  # auto-threshold si None
    top_x=50
)
```
Cela copie :

- Les images au-dessus du seuil calculÃ© dynamiquement.
- Les Top X plus similaires dans deux sous-dossiers distincts.

## 6. ğŸ¥ RecrÃ©er une vidÃ©o (optionnel)

Vous pouvez ensuite recompiler les frames similaires en une vidÃ©o :
```
create_video_from_frames(
    frames_dir="path/to/frames/analysed_frames",
    output_path="path/to/output_video.mp4",
    fps=FPS_TARGET
)
```
