import cv2
import os
import torch
import json
import faiss
import subprocess
import numpy as np
from ultralytics import YOLO
from sentence_transformers import SentenceTransformer


def extract_frames(video_path, output_dir, target_fps=15):
    """
    Extrait les frames d'une vid√©o en ajustant le taux de capture pour correspondre √† un FPS cible (15 FPS),
    tout en conservant la dur√©e originale de la vid√©o.
    """
    # Cr√©er le dossier de sortie s'il n'existe pas
    os.makedirs(output_dir, exist_ok=True)
    
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Erreur: Impossible d'ouvrir la vid√©o.")
        return
    
    original_fps = int(cap.get(cv2.CAP_PROP_FPS))  # FPS de la vid√©o originale
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  # Nombre total de frames
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    duration = total_frames / original_fps if original_fps > 0 else 0  # Dur√©e originale
    
    # frame_interval = max(1, original_fps // target_fps)  # Extraire 1 image toutes les X frames pour respecter 15 FPS
    frame_interval = max(1, 50)  # Extraire 1 image toutes les X frames pour respecter 15 FPS
    frame_number = 0
    extracted_frames = 0
    
    while frame_number < total_frames:
        cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)  # Se positionner sur la bonne frame
        ret, frame = cap.read()
        if not ret:
            break
        
        frame_filename = os.path.join(output_dir, f"frame_{extracted_frames:06d}.jpg")
        cv2.imwrite(frame_filename, frame)
        extracted_frames += 1
        frame_number += frame_interval  # Avancer de l'intervalle calcul√©
    
    cap.release()
    
    # Sauvegarder les m√©tadonn√©es dans un fichier texte
    metadata_file = os.path.join(output_dir, "metadata.txt")
    with open(metadata_file, "w") as f:
        f.write(f"Video Path: {video_path}\n")
        f.write(f"Total Frames Extracted: {extracted_frames}\n")
        f.write(f"Duration (s): {duration:.2f}\n")
        f.write(f"Original FPS: {original_fps}\n")
        f.write(f"Target FPS: {target_fps}\n")
        f.write(f"Resolution: {width}x{height}\n")
    
    print(f"Extraction termin√©e. {extracted_frames} images enregistr√©es √† {target_fps} FPS dans {output_dir}")

#------------------------------------------------------------------------------------------------------------------------------------------------
# Fonction pour redimensionner toutes les images d'un dossier et stocker dans un sous-dossier de Phase2 et mettre √† jour metadata.txt
#-------------------------------------------------------------------------------------------------------------------------------------------------

def resize_images_in_folder(input_folder, output_folder, width, height):
    """
    Redimensionne les images d'un dossier et les stocke dans un sous-dossier "Resized_Data" de Phase2.
    Met √©galement √† jour le fichier metadata.txt avec les nouvelles dimensions.
    """
    
    # V√©rifier si le dossier de sortie existe, sinon le cr√©er
    if not os.path.exists(output_folder):
        os.makedirs(output_folder)
    
    resized_images_count = 0
    
    # Parcourir tous les fichiers du dossier
    for filename in os.listdir(input_folder):
        if filename.lower().endswith((".jpg", ".jpeg", ".png", ".bmp", ".tiff")):  # V√©rification du format image
            input_path = os.path.join(input_folder, filename)
            output_path = os.path.join(output_folder, filename)
            
            # Chargement de l'image
            image = cv2.imread(input_path)
            if image is None:
                print(f"Impossible de lire l'image : {input_path}")
                continue
            
            # Redimensionnement
            resized = cv2.resize(image, (width, height), interpolation=cv2.INTER_AREA)
            
            # Sauvegarde de l'image redimensionn√©e
            cv2.imwrite(output_path, resized)
            print(f"Image redimensionn√©e et sauvegard√©e : {output_path}")
            resized_images_count += 1
    
    # Mise √† jour du fichier metadata.txt
    metadata_file = os.path.join(output_folder, "metadata.txt")
    with open(metadata_file, "w") as f:
        f.write(f"Resized Image Count: {resized_images_count}\n")
        f.write(f"New Resolution: {width}x{height}\n")
    
    print(f"Mise √† jour du fichier metadata.txt termin√©e dans {output_folder}")


if __name__ == "__main__":
    extract_frames("C:\\Users\\ambro\\Desktop\\ProjetS7\\video\\video3.mp4", "FramesOriganales", target_fps=15)
    resize_images_in_folder("FramesOriganales", "Resized_frames", 640, 360)



# --------------------------------------------------------------------------------------------------
# Object detection and text embedding for images in a folder
# --------------------------------------------------------------------------------------------------

# Charger le mod√®le YOLO
model = YOLO("yolo11n.pt")

# Charger le mod√®le de g√©n√©ration d'embeddings
embedder = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')

# Dossier contenant les images
# image_folder = "C:/Users/ambro/Desktop/ProjetS7/images"
image_folder = "C:\\Users\\ambro\\Desktop\\ProjetS7\\Resized_frames"

# Liste des fichiers image
image_extensions = (".jpg", ".jpeg", ".png", ".bmp", ".tiff")
image_files = [f for f in os.listdir(image_folder) if f.lower().endswith(image_extensions)]

# V√©rifier si des images sont trouv√©es
if not image_files:
    print("Aucune image trouv√©e dans le dossier.")
    exit()

# Liste des donn√©es √† stocker
detections_data = []
embeddings_list = []

# Boucle sur chaque image
for image_name in image_files:
    image_path = os.path.join(image_folder, image_name)
    print(f"üì∑ Analyse de : {image_name}")

    # Effectuer la d√©tection
    results = model(image_path)

    # Afficher l'image avec les r√©sultats
    results[0].show()
    # Cr√©er le dossier pour stocker les images analys√©es
    analysed_folder = "analysed_frames"
    os.makedirs(analysed_folder, exist_ok=True)
    # Boucle sur chaque image
    for image_name in image_files:
        image_path = os.path.join(image_folder, image_name)
        print(f"üì∑ Analyse de : {image_name}")

        # Effectuer la d√©tection
        results = model(image_path)

        # Sauvegarder l'image annot√©e
        analysed_image_path = os.path.join(analysed_folder, image_name)
        results[0].save(filename=analysed_image_path)  # Enregistre l'image annot√©e

        print(f"‚úÖ Image annot√©e sauvegard√©e : {analysed_image_path}")

    for result in results:
        boxes = result.boxes.xywh.cpu().numpy()  # (x, y, width, height)
        confs = result.boxes.conf.cpu().numpy()  # Confidence scores
        classes = result.boxes.cls.cpu().numpy()  # Class IDs
        class_names = [result.names[int(cls)] for cls in classes]  # Class names

        for i in range(len(boxes)):
            detection = {
                "image": image_name,
                "class": class_names[i],
                "x": float(boxes[i][0]),
                "y": float(boxes[i][1]),
                "width": float(boxes[i][2]),
                "height": float(boxes[i][3]),
                "confidence": float(confs[i]),
            }
            detections_data.append(detection)

            # G√©n√©rer le texte pour l'embedding
            text_data = f"{image_name} {detection['class']} {detection['x']} {detection['y']} {detection['width']} {detection['height']} {detection['confidence']}"
            embedding = embedder.encode(text_data)
            embeddings_list.append(embedding)

            # Affichage des informations d√©tect√©es
            print(len(embedding))
            print(f"üîπ Objet d√©tect√© : {detection['class']} | Confiance : {detection['confidence']:.2f}")
            print(f"   Position : (x={detection['x']}, y={detection['y']}, w={detection['width']}, h={detection['height']})")

# Conversion en format NumPy pour FAISS
embeddings_np = np.array(embeddings_list).astype('float32')

# Cr√©ation de l'index FAISS
dimension = embeddings_np.shape[1]
index = faiss.IndexFlatL2(dimension)
index.add(embeddings_np)

# Sauvegarde des donn√©es JSON et FAISS
with open("detections.json", "w") as f:
    json.dump(detections_data, f, indent=4)

faiss.write_index(index, "vector_database.faiss")

print("\n‚úÖ Base de donn√©es vectorielle cr√©√©e avec succ√®s !")


# --------------------------------------------------------------------------------------------------
# Recreation of a video
# --------------------------------------------------------------------------------------------------

# Param√®tres
frame_rate = 30  # Ajuste selon ton besoin
input_folder = "analysed_frames"
output_video = "output_video.mp4"

# V√©rifier si le dossier existe
if not os.path.exists(input_folder):
    raise FileNotFoundError(f"Le dossier {input_folder} n'existe pas.")

# Construire la commande FFmpeg
ffmpeg_cmd = [
    "ffmpeg",
    "-framerate", str(frame_rate),
    "-i", f"{input_folder}/frame_%04d.jpg",  # Assurez-vous que les frames sont num√©rot√©es en 0001, 0002...
    "-c:v", "libx264",
    "-pix_fmt", "yuv420p",
    output_video
]

# Ex√©cuter la commande FFmpeg
subprocess.run(ffmpeg_cmd, check=True)

print(f"‚úÖ Vid√©o reconstruite avec succ√®s : {output_video}")
