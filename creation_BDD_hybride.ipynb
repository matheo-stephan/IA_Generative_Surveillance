{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BDD hybride par ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explications\n",
    "\n",
    "Les bases de données vectorielles hybrides, comme **ChromaDB**, combinent **des vecteurs** (embeddings) pour la recherche sémantique avec **des données classiques** (métadonnées) pour le filtrage et l'organisation. Contrairement aux bases de données classiques (SQL), elles sont optimisées pour les requêtes **approximate nearest neighbor (ANN)** et les recherches **hybrides**.\n",
    "\n",
    "---\n",
    "\n",
    "## Structure des collections\n",
    "\n",
    "- 🔹 **Collections vs Tables** :\n",
    "  - En **SQL**, on utilise des **tables** avec des colonnes et des types fixes.\n",
    "  - En **ChromaDB**, on utilise des **collections**, qui stockent des **vecteurs**, des **IDs**, et des **métadonnées JSON**.\n",
    "  \n",
    "- 🔹 **Données stockées** dans chaque collection :\n",
    "  - **Embeddings** : représentations numériques (vecteurs) des données pour la recherche sémantique.\n",
    "  - **IDs uniques** : identifiants pour récupérer des éléments.\n",
    "  - **Métadonnées** : informations complémentaires sous forme de dictionnaire JSON.\n",
    "\n",
    "- 🔹 **Absence de schéma rigide** :\n",
    "  - Contrairement aux bases SQL, **les collections sont flexibles** : pas besoin de définir à l'avance les colonnes ou types de données.\n",
    "  - Les **métadonnées peuvent varier d’un élément à l’autre**.\n",
    "\n",
    "---\n",
    "\n",
    "## Lien entre les collections\n",
    "\n",
    "- 🔗 **Pas de relations directes comme en SQL** (pas de `JOIN`) → On simule les relations avec des **IDs croisés (\"foreign keys\")**.\n",
    "\n",
    "- 📌 **Stratégies pour gérer les relations** :\n",
    "  - Ajouter un **champ ID de référence** dans les métadonnées (ex: `\"author_id\": \"auteur_1\"` pour lier une image à un auteur).\n",
    "  - Effectuer des **requêtes en deux étapes** :\n",
    "    1. Rechercher un élément dans une collection.\n",
    "    2. Utiliser son ID pour récupérer les données associées dans une autre collection.\n",
    "\n",
    "  - Exemple d'association **1-N** (un auteur a plusieurs images) :\n",
    "\n",
    "    ```python\n",
    "    # Récupérer toutes les images d'un auteur donné\n",
    "    collection.get(where={\"author_id\": \"auteur_1\"})\n",
    "    ```\n",
    "\n",
    "  - 📍 Contrairement à SQL, pas de **contrainte d’intégrité référentielle** → Il faut gérer manuellement la suppression et la mise à jour des liens.\n",
    "\n",
    "---\n",
    "\n",
    "## Métadonnées\n",
    "\n",
    "- 🏷️ **Stockées en JSON**, flexibles, et utilisées pour le **filtrage rapide**.\n",
    "- 🔍 **Utilisées pour des recherches hybrides** :\n",
    "  - **Recherche vectorielle** pour la similarité sémantique.\n",
    "  - **Filtrage classique** sur des attributs spécifiques.\n",
    "  \n",
    "- 📊 **Avantages des métadonnées** :\n",
    "  - Permettent d’ajouter des **catégories, tags, sources, relations** aux données vectorielles.\n",
    "  - Accélèrent la recherche en limitant l’espace de recherche (ex: **ne chercher que dans une catégorie donnée**).\n",
    "\n",
    "- ✅ **Exemple de requête hybride** (trouver les 3 images les plus proches d’un vecteur, mais uniquement dans la catégorie \"animal\") :\n",
    "\n",
    "  ```python\n",
    "  collection.query(\n",
    "      query_embeddings=[[0.1, 0.2, 0.3]],\n",
    "      n_results=3,\n",
    "      where={\"category\": \"animal\"}\n",
    "  )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## regroupement de toutes les variables en 1 table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du client et de la base locale\n",
    "client = chromadb.PersistentClient(path=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une collection\n",
    "detection = client.get_or_create_collection(\"detection\")\n",
    "Image = client.get_or_create_collection(\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction d'ajout dans la collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ajout de catégories obligatoires pour les collections\n",
    "\n",
    "# Ajout de documents avec vecteurs + métadonnées\n",
    "def add_detection(ids, embeddings, metadatas):\n",
    "    detection.add(\n",
    "        ids=ids,\n",
    "        embeddings=embeddings,\n",
    "        metadatas=metadatas\n",
    "    )\n",
    "\n",
    "# REFLEXION : on a une ligne par objet détecté, alors qu'il faudrait une ligne par frame \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Génération aléatoires de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Add of existing embedding ID: 0\n",
      "Add of existing embedding ID: 1\n",
      "Add of existing embedding ID: 2\n",
      "Add of existing embedding ID: 3\n",
      "Add of existing embedding ID: 4\n",
      "Add of existing embedding ID: 5\n",
      "Add of existing embedding ID: 6\n",
      "Add of existing embedding ID: 7\n",
      "Add of existing embedding ID: 8\n",
      "Add of existing embedding ID: 9\n",
      "Insert of existing embedding ID: 0\n",
      "Insert of existing embedding ID: 1\n",
      "Insert of existing embedding ID: 2\n",
      "Insert of existing embedding ID: 3\n",
      "Insert of existing embedding ID: 4\n",
      "Insert of existing embedding ID: 5\n",
      "Insert of existing embedding ID: 6\n",
      "Insert of existing embedding ID: 7\n",
      "Insert of existing embedding ID: 8\n",
      "Insert of existing embedding ID: 9\n"
     ]
    }
   ],
   "source": [
    "# génération aléatoire de données\n",
    "import random\n",
    "\n",
    "ids = [str(i) for i in range(10)]\n",
    "embeddings = [[random.random() for _ in range(3)] for _ in range(10)]\n",
    "metadatas = [{\n",
    "    \"nom_image\": f\"frame{i:03d}.jpg\",\n",
    "    \"num_frame\": str(i),\n",
    "    \"nom_video\": f\"video{i//10:03d}.mp4\",\n",
    "    \"nb_frames_tot\": \"150\",\n",
    "    \"fps\": \"15\",\n",
    "    \"resolution\": \"1920x1080\",\n",
    "    \"class_name\": random.choice([\"person\", \"car\", \"animal\"]),\n",
    "    \"x\": str(random.randint(0, 1920)),\n",
    "    \"y\": str(random.randint(0, 1080)),\n",
    "    \"height\": str(random.randint(100, 500)),\n",
    "    \"width\": str(random.randint(100, 500))\n",
    "} for i in range(10)]\n",
    "\n",
    "add_detection(ids, embeddings, metadatas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affichage de toutes les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 ID: 1\n",
      "🧠 Embedding: [0.1        0.2        0.30000001]\n",
      "📌 Métadonnées: {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}\n",
      "----------------------------------------\n",
      "🔹 ID: 2\n",
      "🧠 Embedding: [0.1        0.2        0.30000001]\n",
      "📌 Métadonnées: {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}\n",
      "----------------------------------------\n",
      "🔹 ID: 4\n",
      "🧠 Embedding: [0.1        0.2        0.30000001]\n",
      "📌 Métadonnées: {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}\n",
      "----------------------------------------\n",
      "🔹 ID: yippi\n",
      "🧠 Embedding: [0.1        0.2        0.30000001]\n",
      "📌 Métadonnées: {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}\n",
      "----------------------------------------\n",
      "🔹 ID: 0\n",
      "🧠 Embedding: [0.27235115 0.71025938 0.78482819]\n",
      "📌 Métadonnées: {'class_name': 'animal', 'fps': '15', 'height': '407', 'nb_frames_tot': '150', 'nom_image': 'frame000.jpg', 'nom_video': 'video000.mp4', 'num_frame': '0', 'resolution': '1920x1080', 'width': '467', 'x': '14', 'y': '572'}\n",
      "----------------------------------------\n",
      "🔹 ID: 3\n",
      "🧠 Embedding: [0.20126073 0.76372963 0.89835179]\n",
      "📌 Métadonnées: {'class_name': 'animal', 'fps': '15', 'height': '169', 'nb_frames_tot': '150', 'nom_image': 'frame003.jpg', 'nom_video': 'video000.mp4', 'num_frame': '3', 'resolution': '1920x1080', 'width': '199', 'x': '335', 'y': '914'}\n",
      "----------------------------------------\n",
      "🔹 ID: 5\n",
      "🧠 Embedding: [0.03948078 0.48359433 0.20216314]\n",
      "📌 Métadonnées: {'class_name': 'animal', 'fps': '15', 'height': '286', 'nb_frames_tot': '150', 'nom_image': 'frame005.jpg', 'nom_video': 'video000.mp4', 'num_frame': '5', 'resolution': '1920x1080', 'width': '373', 'x': '1236', 'y': '599'}\n",
      "----------------------------------------\n",
      "🔹 ID: 6\n",
      "🧠 Embedding: [0.17443036 0.47820887 0.24937223]\n",
      "📌 Métadonnées: {'class_name': 'animal', 'fps': '15', 'height': '362', 'nb_frames_tot': '150', 'nom_image': 'frame006.jpg', 'nom_video': 'video000.mp4', 'num_frame': '6', 'resolution': '1920x1080', 'width': '135', 'x': '315', 'y': '86'}\n",
      "----------------------------------------\n",
      "🔹 ID: 7\n",
      "🧠 Embedding: [0.96447498 0.1020478  0.39577025]\n",
      "📌 Métadonnées: {'class_name': 'person', 'fps': '15', 'height': '167', 'nb_frames_tot': '150', 'nom_image': 'frame007.jpg', 'nom_video': 'video000.mp4', 'num_frame': '7', 'resolution': '1920x1080', 'width': '421', 'x': '863', 'y': '44'}\n",
      "----------------------------------------\n",
      "🔹 ID: 8\n",
      "🧠 Embedding: [0.95667899 0.45595729 0.34813011]\n",
      "📌 Métadonnées: {'class_name': 'animal', 'fps': '15', 'height': '248', 'nb_frames_tot': '150', 'nom_image': 'frame008.jpg', 'nom_video': 'video000.mp4', 'num_frame': '8', 'resolution': '1920x1080', 'width': '102', 'x': '839', 'y': '310'}\n",
      "----------------------------------------\n",
      "🔹 ID: 9\n",
      "🧠 Embedding: [0.8124156  0.85343295 0.81834185]\n",
      "📌 Métadonnées: {'class_name': 'car', 'fps': '15', 'height': '480', 'nb_frames_tot': '150', 'nom_image': 'frame009.jpg', 'nom_video': 'video000.mp4', 'num_frame': '9', 'resolution': '1920x1080', 'width': '341', 'x': '546', 'y': '1027'}\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Récupérer toutes les données (ids, embeddings, metadatas)\n",
    "all_data = detection.get(include=[\"embeddings\", \"metadatas\"])\n",
    "\n",
    "# Afficher tout le contenu\n",
    "for i in range(len(all_data[\"ids\"])):\n",
    "    print(f\"🔹 ID: {all_data['ids'][i]}\")\n",
    "    if all_data['embeddings'] is not None:\n",
    "        print(f\"🧠 Embedding: {all_data['embeddings'][i]}\")\n",
    "    print(f\"📌 Métadonnées: {all_data['metadatas'][i]}\")\n",
    "    print(\"-\" * 40)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_query(collection, query_vector=[0], query={\"\":\"\"}, max_dist=0.5):\n",
    "    # Obtenir le nombre de documents dans la collection\n",
    "    num_documents = len(collection.get()[\"ids\"])\n",
    "\n",
    "    # Recherche hybride (similitude vectorielle + filtre sur la catégorie)\n",
    "    results = detection.query(\n",
    "        query_embeddings=[query_vector],\n",
    "        n_results=num_documents,  # Nombre de résultats souhaités\n",
    "        where=query,  # Filtrage par métadonnée\n",
    "        include=[\"embeddings\", \"metadatas\", \"distances\"],\n",
    "    )\n",
    "\n",
    "    filtered_results = {    # Filtrer les résultats pour n'afficher que ceux avec une distance inférieure à 0.5\n",
    "            \"ids\": [],\n",
    "            \"embeddings\": [],\n",
    "            \"metadatas\": [],\n",
    "            \"distances\": []\n",
    "        }\n",
    "\n",
    "    for i in range(len(results[\"ids\"])):\n",
    "        if results[\"distances\"][i][0] < max_dist:  # Access the first element of the list\n",
    "            filtered_results[\"ids\"].append(results[\"ids\"][i])\n",
    "            filtered_results[\"embeddings\"].append(results[\"embeddings\"][i])\n",
    "            filtered_results[\"metadatas\"].append(results[\"metadatas\"][i])\n",
    "            filtered_results[\"distances\"].append(results[\"distances\"][i][0])  # Access the first element of the list\n",
    "\n",
    "    results = filtered_results\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 ID: ['yippi', '4', '2', '1']\n",
      "🧠 Embedding: [[0.1        0.2        0.30000001]\n",
      " [0.1        0.2        0.30000001]\n",
      " [0.1        0.2        0.30000001]\n",
      " [0.1        0.2        0.30000001]]\n",
      "📌 Métadonnées: [{'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}, {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}, {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}, {'class_name': 'person', 'fps': '15', 'height': '400', 'nb_frames_tot': '150', 'nom_image': 'frame001.jpg', 'nom_video': 'video001.mp4', 'num_frame': '1', 'resolution': '1920x1080', 'width': '100', 'x': '400', 'y': '200'}]\n",
      "📏 Distance: 0.679999960660935\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "results = ask_query(detection, query_vector=[0.9, 0.4, 0.3], query={\"height\":\"400\"}, max_dist=0.7)\n",
    "\n",
    "# Affichage des résultats de la recherche\n",
    "for i in range(len(results[\"ids\"])):\n",
    "    print(f\"🔹 ID: {results['ids'][i]}\")\n",
    "    print(f\"🧠 Embedding: {results['embeddings'][i]}\")\n",
    "    print(f\"📌 Métadonnées: {results['metadatas'][i]}\")\n",
    "    print(f\"📏 Distance: {results['distances'][i]}\")\n",
    "    print(\"-\" * 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VGS_proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
